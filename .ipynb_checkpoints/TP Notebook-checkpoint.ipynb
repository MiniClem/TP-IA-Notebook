{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression linéaire par moindres carrés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les imports du notebook complet :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import random\n",
    "from sklearn import neighbors\n",
    "from sklearn.datasets import load_iris  # les donn ́ees iris sont charg ́ees\n",
    "from sklearn.datasets import load_boston  # les donn ́ees iris sont charg ́ees\n",
    "from sklearn.datasets import load_diabetes  # les donn ́ees iris sont charg ́ees\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pylab as pl  # permet de remplacer le nom \"pylab\" par \"pl\"\n",
    "import numpy as np\n",
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soit l'algorithme de régression linéaire par moindre carrés suivant : <br>\n",
    "1) Ajouter le vecteur 1 à la matrice $X \\in \\mathbb{R}^{n x d}$ contenant les données $x_{i=1}^{n}$<br>\n",
    "2) Calculer $w = (X^{T}X)^{-1}X^{T}y$, avec $y = y_{i=1}^{n} \\in \\mathbb{R}^{n}$<br>\n",
    "3) Retourner $w$<br>\n",
    "On se propose de coder l'implémentation de la régression linéaire par moindre carrés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg(X, Y):\n",
    "    ones = np.ones((len(X), 1))\n",
    "    Xb = np.concatenate((X, ones), axis=1)\n",
    "    \n",
    "    Xt = np.transpose(Xb)\n",
    "    w = np.dot(np.dot(np.linalg.inv(np.dot(Xt, Xb)), Xt), Y)\n",
    "    \n",
    "    print(w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la réalisation de l'exercice nous utiliserons un jeu de données bi-dimensionnelle contenues dans un fichier.<br>\n",
    "On ouvre le fichier et on stocke les valeurs dans 2 variables ($x$ et $y$) que nous réutiliserons par la suite.<br>\n",
    "La variable $x$ est un vecteur en 2 dimensions, la variable $y$ est en 1 dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le fichier\n",
    "tt = np.loadtxt(\"dataRegLin2D.txt\")\n",
    "x = tt[:, :2]\n",
    "y = tt[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On représente les données sur un graphe en 3 dimensions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def graph3D(x,y):\n",
    "    fig = pl.figure(\"Visualisation du jeu de données\")\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(x[:,0],x[:,1],y, c=y)\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_zlabel('y')\n",
    "    pl.show()\n",
    "\n",
    "# Graphe 3D\n",
    "graph3D(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A première vue il y a une dépendance linéaire entre les étiquettes $x_{i}^{1}$, $x_{i}^{2}$ et $y_i$ selon l'angle de vue.\n",
    "\n",
    "On va donc chercher si les valeurs sont bien dépendantes ou non. Pour cela on affiche les résultats de la régression linéaire des valeurs du fichier sur un graphe en 2D.<br>\n",
    "En premier lieu on étudie les dépendances entre les étiquettes $x_{i}^{1}$ et $y_i$ (en <span style=\"color:red\">rouge</span>) puis les étiquettes $x_{i}^{2}$ et $y_i$ (en <span style=\"color:blue\">bleu</span>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Première étiquette\n",
    "pl.figure(\"x^(1)\")\n",
    "pl.scatter(x[:, 0], y, c='red')\n",
    "pl.show()\n",
    "\n",
    "# Seconde étiquette\n",
    "pl.figure(\"x^(2)\")\n",
    "pl.scatter(x[:, 1], y, c='blue')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que les données de la <span style=\"color:red\">première dimension</span> de x (i.e $x_{i}^{1}$) est \"mal\" répartie et produit une dispersion de points qui ne semblent pas avoir de cohérences entre eux.<br>\n",
    "L'inverse se produit pour les données de la <span style=\"color:blue\">seconde dimension</span> de x (i.e $x_{i}^{2}$) qui ont l'air d'être facilement approchées par une droite de régression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche maintenant à calculer les droites de régression dans chacun des cas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres de régression\n",
    "x0p = reg(x[:, [0]], y)  # [ 0.44979209 -0.59832595]\n",
    "x1p = reg(x[:, [1]], y)  # [ 1.43100678 -0.64475543]\n",
    "    \n",
    "def lin(x, xp):\n",
    "    return xp[0] * x + xp[1]\n",
    "    \n",
    "# Graphiques 2D\n",
    "pl.figure(\"Plotting des valeurs de x et leur droites de régression calculées\")\n",
    "pl.scatter(x[:, 0], y, c='red')\n",
    "pl.scatter(x[:, 1], y, c='blue')\n",
    "pl.plot(x, lin(x, x0p), color='red')\n",
    "pl.plot(x, lin(x, x1p), color='blue')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut remarquer que les points <span style=\"color:red\">rouge</span> de $x_{i}^{1}$ et $y_{i}$ sont dispersés et la droite de régression qui les représente passe grossièrement au milieu de tous les points, mais la cohérence des points entre eux est faible.<br>\n",
    "En revanche les points <span style=\"color:blue\">bleus</span> sont bien alignés et la droite de régression qui en résulte est  proche des points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va calculer un vecteur de pondération <i>w</i> afin de réaliser une fonction qui à partir de valeurs $x_{test}$ permet de prédire le label $y_{test}$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du vecteur de pondération w\n",
    "w = reg(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On donne la formule de la fonction de la droite de régression, soit $x \\in \\mathbb{R}^{2}, f(x) =  w_{1}.x_{1} + w_{2}.x_{2} + w_{3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_reg(x, w):\n",
    "    return w[0]*x[0] + w[1]*x[1] +  w[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'erreur au carré entre les valeurs prédites et celles de l'ensemble des données réelles\n",
    "err_pred = []\n",
    "for i in range(len(x)):\n",
    "    # Calcul de la valeur prédite\n",
    "    y_pred = pred_reg(x[i], w)\n",
    "    # Différence entre le label prédit et le label réel\n",
    "    err_pred.append(abs(y[i] - y_pred)**2)\n",
    "print(err_pred[:10], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyenne d'erreur carrée\n",
    "stat.mean(err_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On trouve une prédiction proche à 2 décimales en moyenne des valeurs d'origines grâce à la fonction de prédiction entraînée par la méthode des moindres carrés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression linéaire avec Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons jusque là réalisé la méthode \"à la main\" en suivant l'algorithme de régression linéaire des moindres carrés.<br>\n",
    "Maintenant nous allons réaliser implémenter et analyser de nouveaux algorithmes de régressions linéaires avec la librairie Scikit-learn.<br>\n",
    "\n",
    "Pour commencer on va recalculer avec les nouveaux outils les données de l'exercice précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.3,\n",
    "                                                        random_state=random.seed(123))\n",
    "model = LinearRegression().fit(X_train, Y_train)\n",
    "r_sq = model.score(X_train, Y_train)\n",
    "print('coefficient of determination:', r_sq)\n",
    "print('intercept:', model.intercept_)\n",
    "print('slope:', model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour rappel nous avions trouvé comme paramètres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions des labels y\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred[:10], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatage des données\n",
    "pred = np.array(y_pred).reshape(-1, 1)\n",
    "\n",
    "# Calcul de l'erreur moyenne carré pour chaque valeurs\n",
    "print(mean_squared_error(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prédiction calculée par scikit-learn est très similaire à celle trouvée précédemment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut appliquer cette méthode sur des jeux de données réels différents, par exemple le prix des maison à Boston ou sur les chiffres du diabète.<br>\n",
    "\n",
    "## Diabète<br>\n",
    "Chargement des données depuis scikit-learn.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données de diabète\n",
    "diabete = load_diabetes()\n",
    "X_diabete = diabete.data\n",
    "Y_diabete = diabete.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les attributs disponibles dans ces données sont :\n",
    "- age in years\n",
    "- sex\n",
    "- bmi body mass index\n",
    "- bp average blood pressure\n",
    "- s1 tc, T-Cells (a type of white blood cells)\n",
    "- s2 ldl, low-density lipoproteins\n",
    "- s3 hdl, high-density lipoproteins\n",
    "- s4 tch, thyroid stimulating hormone\n",
    "- s5 ltg, lamotrigine\n",
    "- s6 glu, blood sugar level\n",
    "\n",
    "On réalise un jeu de données et on calcule la régression linéaire avec scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jeux de données de tests et d'entrainements créés à partir de l'ensemble des données importées\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_diabete, Y_diabete, test_size=0.3,\n",
    "                                                        random_state=random.seed(123))\n",
    "#Calcul du modèle de régression linéaire\n",
    "model = LinearRegression().fit(X_train, Y_train)\n",
    "r_sq = model.score(X_train, Y_train)\n",
    "print('coefficient of determination:', r_sq)\n",
    "print('intercept:', model.intercept_)\n",
    "print('slope:', model.coef_)\n",
    "\n",
    "# Prédiction de données à partir des données de test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyenne de l'erreur au carré\n",
    "print(mean_squared_error(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'erreur au carré est très importante, le modèle n'est pas bon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston<br>\n",
    "Chargement des données depuis scikit-learn.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données de Boston\n",
    "boston = load_boston()\n",
    "X_boston = boston.data\n",
    "Y_boston = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les attributs du jeu de données sont :\n",
    "- CRIM per capita crime rate by town\n",
    "- ZN proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS proportion of non-retail business acres per town\n",
    "- CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- NOX nitric oxides concentration (parts per 10 million)\n",
    "- RM average number of rooms per dwelling\n",
    "- AGE proportion of owner-occupied units built prior to 1940\n",
    "- DIS weighted distances to five Boston employment centres\n",
    "- RAD index of accessibility to radial highways\n",
    "- TAX full-value property-tax rate per \\$10,000\n",
    "- PTRATIO pupil-teacher ratio by town\n",
    "- B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- LSTAT % lower status of the population\n",
    "- MEDV Median value of owner-occupied homes in \\$1000’s\n",
    "\n",
    "On réalise un jeu de données et on calcule la régression linéaire avec scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jeux de données de tests et d'entrainements créés à partir de l'ensemble des données importées\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_boston, Y_boston, test_size=0.3,\n",
    "                                                        random_state=random.seed(123))\n",
    "\n",
    "#Calcul du modèle de régression linéaire\n",
    "model = LinearRegression().fit(X_train, Y_train)\n",
    "r_sq = model.score(X_train, Y_train)\n",
    "print('coefficient of determination:', r_sq)\n",
    "print('intercept:', model.intercept_)\n",
    "print('slope:', model.coef_)\n",
    "\n",
    "# Prédiction de données à partir des données de test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyenne de l'erreur au carré\n",
    "print(mean_squared_error(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'écart est moins important entre le modèle prédit et les données réelles, il est possible que le modèle soit bon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression par Ridge et Lasso\n",
    "La régression ridge et lasso sont des extensions de la régression linéaire par moindres carrés permettant d’éviter le risque de sur-apprentissage.<br>\n",
    "Nous allons appliquer une régression Ridge et Lasso avec un coefficient $\\alpha = 1.0$ sur les données de Boston et comparer les deux solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_boston, Y_boston, test_size=0.3,\n",
    "                                                        random_state=random.seed(123))\n",
    "\n",
    "# alp signifie que le coefficient alpha utilisé est celui par défaut, False sinon pour calculer un coefficient optimisé\n",
    "def ridge_boston(alp):\n",
    "    alpha = 1.0 if alp else alphaRidge(X_train, Y_train)['alpha']\n",
    "    print(\"alpha =\", alpha)\n",
    "\n",
    "    model = Ridge(alpha=alpha).fit(X_train, Y_train)\n",
    "    r_sq = model.score(X_train, Y_train)\n",
    "    print('coefficient of determination:', r_sq)\n",
    "    print('intercept:', model.intercept_)\n",
    "    print('slope:', model.coef_)\n",
    "\n",
    "    # Prédiction\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Erreur moyenne carrée :', mean_squared_error(Y_test, y_pred))\n",
    "\n",
    "# alp signifie que le coefficient alpha utilisé est celui par défaut, False sinon pour calculer un coefficient optimisé\n",
    "def lasso_boston(alp):\n",
    "    alpha = 1.0 if alp else alphaLasso(X_train, Y_train)['alpha']\n",
    "    print(\"alpha =\", alpha)\n",
    "\n",
    "    model = Lasso(alpha=alpha).fit(X_train, Y_train)\n",
    "    r_sq = model.score(X_train, Y_train)\n",
    "    print('coefficient of determination:', r_sq)\n",
    "    print('intercept:', model.intercept_)\n",
    "    print('slope:', model.coef_)\n",
    "\n",
    "    # Prédiction\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Erreur moyenne carrée :', mean_squared_error(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du modèle de régression linéaire par Ridge\n",
    "# True signifie que le coefficient alpha utilisé est celui par défaut\n",
    "ridge_boston(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du modèle de régression linéaire par Lasso\n",
    "# True signifie que le coefficient alpha utilisé est celui par défaut\n",
    "lasso_boston(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les deux méthodes donnent des résultats proches entre eux et par rapport à la méthode des moindres carrés.<br>\n",
    "Nous allons maintenant chercher à calculer le meilleur coefficent $\\alpha$ pour les deux nouvelles méthodes de régression linéaire. Pour cela nous utiliserons la méthode de cross-validation sur une grille de valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Méthodes pour déterminer le meilleure coefficient alpha les régressions par Ridge et Lasso\n",
    "\n",
    "def alphaRidge(X, y):\n",
    "    alphas = np.logspace(-3, -1, 20)\n",
    "    gscv = GridSearchCV(Ridge(), dict(alpha=alphas), cv=5).fit(X, y)\n",
    "    return gscv.best_params_\n",
    "\n",
    "\n",
    "def alphaLasso(X, y):\n",
    "    alphas = np.logspace(-3, -1, 20)\n",
    "    gscv = GridSearchCV(Lasso(), dict(alpha=alphas), cv=5).fit(X, y)\n",
    "    return gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du meilleur coefficient alpha pour la méthode du Ridge\n",
    "alpha = alphaRidge(X_train, Y_train)['alpha']\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du meilleur coefficient alpha pour la méthode du Lasso\n",
    "alpha = alphaLasso(X_train, Y_train)['alpha']\n",
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut donc utiliser le meilleur coefficient $\\alpha$ pour les deux méthodes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False signifie que le coefficient alpha utilisé est celui optimisé par le calcul d'un coefficient en \n",
    "# fonction des jeux de données\n",
    "ridge_boston(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False signifie que le coefficient alpha utilisé est celui optimisé par le calcul d'un coefficient en \n",
    "# fonction des jeux de données\n",
    "lasso_boston(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec la valeur du coefficient $\\alpha$ optimisé, on se rend compte que les deux modèles de régression renvoient des résultats très similaires. Le coefficient $\\alpha$ est bien ajusté par rapport au jeux de données et l'erreur est minimisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
